var documenterSearchIndex = {"docs":
[{"location":"getting_started/#Getting-started","page":"Getting Started","title":"Getting started","text":"This package provides tools to learn and use word embeddings with Word2Vec and its Context Encoder (ConEc) extension. It focuses on training CBOW‑style Word2Vec models, constructing sparse context representations, and applying them to small text datasets for evaluation and visualization.","category":"section"},{"location":"getting_started/#General-idea","page":"Getting Started","title":"General idea","text":"The core idea is to represent each word by a real‑valued vector (an embedding) such that words appearing in similar contexts have similar vectors. Word2Vec learns these embeddings from text using neural models like Continuous Bag of Words (CBOW), which predicts a target word from its surrounding context, while ConEc extends this by encoding richer, sparse context information to refine the learned representations.","category":"section"},{"location":"getting_started/#Installation-and-loading","page":"Getting Started","title":"Installation and loading","text":"First, activate your project and add the package.\n\nusing Pkg\n\nPkg.activate(\"Word2Vec\")\n\ninclude(\"src/Word2Vec.jl\")\nusing .Word2Vec","category":"section"},{"location":"getting_started/#Loading-pre‑trained-embeddings","page":"Getting Started","title":"Loading pre‑trained embeddings","text":"You can load a standard Word2Vec file in either text or Gensim‑style binary format. The format is detected automatically.\n\nemb_map = load_word2vec(\"test/data/word2vec.bin\")    # or \"word2vec.txt\"\n\nemb_map is a Dict{String, Vector{Float64}} mapping each word to its embedding vector.","category":"section"},{"location":"getting_started/#Building-a-Word2Vec-model","page":"Getting Started","title":"Building a Word2Vec model","text":"To work with embeddings efficiently, convert the dictionary into a Word2VecModel.\n\nmodel = load_pretrained_model(\"test/data/word2vec.txt\")\n\nWord2VecModel stores all embeddings in a dense matrix, together with the vocabulary, a word‑to‑index map, and precomputed vector norms. This is useful for later similarity or nearest‑neighbor queries.","category":"section"},{"location":"getting_started/#Getting-embeddings-for-words","page":"Getting Started","title":"Getting embeddings for words","text":"Once a model is loaded, you can access the embedding of a word as a view into the underlying matrix.\n\nv_human = get_embedding(model, \"human\")\n\nprintln(size(v_human))  # (embedding_dim,)\n\nThe returned object behaves like a dense vector and can be used with standard Julia linear‑algebra operations, such as dot products or norms.","category":"section"},{"location":"#Word2Vec","page":"Home","title":"Word2Vec","text":"Documentation for Word2Vec.\n\n","category":"section"},{"location":"#Word2Vec.Word2VecModel","page":"Home","title":"Word2Vec.Word2VecModel","text":"Word2VecModel\n\nUnified in-memory representation for Word2Vec embeddings.\n\nFields:\n\nvocab::Vector{String}         \tlist of words\nembeddings::Matrix{Float32}   \tsize = (dim, vocab_size)\nvector_norms::Vector{Float32} \tnorms of embedding vectors\nwordtoindex::Dict{String,Int}  \tmaps words to column indices\n\n\n\n\n\n","category":"type"},{"location":"#Word2Vec.detect_embedding_format-Tuple{AbstractString}","page":"Home","title":"Word2Vec.detect_embedding_format","text":"detect_embedding_format(path::String) :: Symbol\n\nHeuristically detects whether a Word2Vec embedding file is in text or binary format.\n\nArguments\n\npath::String: Path to the embedding file.\n\nReturns\n\n:text if the file appears to be in text format (word float float ...).\n:binary if the file appears to be in binary Word2Vec format.\n\nNotes\n\nThe function first checks the file extension: files ending in .bin are assumed to be binary.\nIf the extension does not indicate the format, the function inspects only the first few non-empty lines of the file.\nA line is classified as text if it has a non-numeric first token and the following tokens resemble floating-point numbers.\nOnly a small prefix of the file is scanned to avoid loading large files into memory.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.from_dict_data-Union{Tuple{Dict{String, Vector{T}}}, Tuple{T}} where T<:AbstractFloat","page":"Home","title":"Word2Vec.from_dict_data","text":"from_dict_data(embeddings_map::Dict{String,Vector{T}})\n\nConstructs a Word2VecModel from (word => vector) mappings.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.get_embedding-Tuple{Word2VecModel, String}","page":"Home","title":"Word2Vec.get_embedding","text":"get_embedding(model::Word2VecModel, word::AbstractString)\n\nReturns a view of the embedding vector for a given word.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.get_embedding_norm-Tuple{Word2VecModel, String}","page":"Home","title":"Word2Vec.get_embedding_norm","text":"get_embedding_norm(model::Word2VecModel, word::AbstractString)\n\nReturns the precomputed norm of an embedding vector for a given word.\n\nThrows an error if the given word is not in the vocabulary of the model.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.load_binary_embeddings-Tuple{String}","page":"Home","title":"Word2Vec.load_binary_embeddings","text":"load_binary_embeddings(path::String) :: Dict{String, Vector{Float64}}\n\nLoads Word2Vec embeddings from a Gensim binary-format file.\n\nArguments\n\npath::String: Path to the Gensim binary-format embedding file.\n\nReturns\n\nDict{String, Vector{Float64}}: Dictionary mapping words to embedding vectors.\n\nNotes\n\nGensim hybrid format: Text header \"vocab_size dim\", ASCII words (space-terminated), binary Float32 vectors.\nVectors are automatically converted from Float32 to Float64 for consistency.\nMatches output of model.wv.save_word2vec_format(binary=True) from gensim.test.utils.\nNo pure-binary Int32 header support (gensim-specific).\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.load_pretrained_model-Tuple{String}","page":"Home","title":"Word2Vec.load_pretrained_model","text":"load_pretrained_model(path::String; file_type::Symbol = :auto) -> Word2VecModel\n\nLoads embeddings from disk and returns a dense Word2Vec model.\n\nArguments\n\npath: Filesystem path to the embeddings.\nfile_type: :auto to detect, or explicitly :binary / :text.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.load_text_embeddings-Tuple{String}","page":"Home","title":"Word2Vec.load_text_embeddings","text":"load_text_embeddings(path::String) :: Dict{String, Vector{Float64}}\n\nLoads Word2Vec embeddings from a text-format file.\n\nArguments\n\npath::String: Path to the text-format Word2Vec embedding file.\n\nReturns\n\nDict{String, Vector{Float64}}: Dictionary mapping words to embedding vectors.\n\nNotes\n\nEach line: word float float ... (header lines auto-skipped).\nSkips lines where first token is numeric or vectors can't be parsed.\nReads entire file into memory.\n\n\n\n\n\n","category":"method"},{"location":"#Word2Vec.load_word2vec-Tuple{String}","page":"Home","title":"Word2Vec.load_word2vec","text":"load_word2vec(path::String) :: Dict{String, Vector{Float64}}\n\nLoads Word2Vec embeddings from a file, automatically detecting whether the file is in text or binary format.\n\nArguments\n\npath::String: Path to the Word2Vec embedding file.\n\nReturns\n\nDict{String, Vector{Float64}}: Dictionary mapping words to embedding vectors.\n\nNotes\n\nUses detect_embedding_format to determine file format.\nText files: word float float ... (skips numeric header lines).\nBinary files: Gensim hybrid format (text header \"vocab_size dim\", ASCII words, binary Float32 vectors).\nBinary vectors are converted to Float64 for consistency.\nLarge models require substantial RAM.\n\n\n\n\n\n","category":"method"}]
}
